---
title: 训练与微调
tags:
  - LLM
  - 微调
---

## 训练与微调

### 基本概念
微调（Fine-tuning）是指在已经预训练好的大模型基础上，利用==特定领域或任务的数据==对模型进行再次训练的过程。

==主要目的==是让模型更好地适应特定应用场景，提高在特定任务上的表现。通过微调，可以让通用大模型具备更强的专业能力、理解特定领域的术语和知识，或者更好地满足用户的个性化需求。


::: tip 常见面试题
:::

::: details 问题1.  微调和RAG的区别,什么时候用微调？什么时候用RAG？


基本区别：
- **微调（Fine-tuning）**是在已有的大模型上，针对领域数据或领域任务，对模型参数进一步训练。模型参数会发生改变，能让模型"长期"具备某种能力或知识。
- **RAG（Retrieval-Augmented Generation）**是一种将检索和LLM结合的技术。在不改变已有的模型基础上，“外挂”知识库，增强模型能力。


| 维度 | 微调 | RAG |
|------|------|-----|
| **1.性能成本** | 训练代价高，推理成本小 | 无训练代价，推理时高 |
| **【1延申】更新频率** | 更新慢 | 更新快，甚至可以实时 |
| **【1延申】部署场景** | 要求时延低 | 时延不紧张  |
| **2.效果依赖** | 微调的数据质量和覆盖度 | 知识库的质量和检索质量 |
| **3.实际场景** | 客服（业务逻辑和特定话术）<br> 代码助手（特定语言和框架）<br> 医疗大模型、法律大模型……| 企业知识问答（内部知识库）<br> 学术助手（论文检索和引用） <br> 新闻助手、舆论问答等实时类场景 |
| **4.使用时机**| 让模型具备的风格话术、专业术语<br>知识变化不频繁，可定期更新<br>时延要求低 | 知识更新频繁、甚至有实时性要求<br>知识库属于私有、商业机密<br>答案有依据，知识可溯源|


**总结**：微调是"改造"模型本身，RAG是"外挂"知识库。微调适合模型能力长期固化，RAG适合灵活扩展和实时更新知识。

:::


::: details 问题2：微调时，全量微调和高效微调有什么区别？各自在什么时机用？

区别：
- **全量微调（Full Fine-tuning）**更新所有的模型参数，需要的数据量大、训练时间长，但效果往往比较好
- **高效微调（Parameter-Efficient Fine-tuning, PEFT）**更新少量的参数、训练快、效率高，效果也能接近全量微调。

| 维度 | 全量微调 | 高效微调 |
|------|----------|----------|
|**参数量**| 所有参数 | 少部分参数(1-10%) |
|**效果**| 通常最好| 接近全量微调|
|**训练速度**| 慢 | 快 |
|**数据需求**| 大量高质量数据 | 少量高质量数据 |
| **时机** | 数据、训练资源充足<br> 效果精度要求高 <br>  部署后很少更新| 数据有限<br>快速迭代 |
:::


### LORA
### QLORA

### 