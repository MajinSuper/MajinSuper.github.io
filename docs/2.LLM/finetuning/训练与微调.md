---
title: 训练与微调
tags:
  - LLM
  - 微调
createTime: 2025-09-20 09:44:31
permalink: /article/finetuning/
---

## 训练与微调

### 基本概念
微调（Fine-tuning）是指在已经预训练好的大模型基础上，利用==特定领域或任务的数据==对模型进行再次训练的过程。

==主要目的==是让模型更好地适应特定应用场景，提高在==特定任务上的表现==。通过微调，可以让通用大模型具备更强的专业能力、理解特定领域的术语和知识，或者更好地满足用户的个性化需求。


::: tip 常见面试题
:::

::: details 问题1.  微调和RAG的区别,什么时候用微调？什么时候用RAG？


基本区别：
- **微调（Fine-tuning）**是在已有的大模型上，针对==领域数据或领域任务==，对模型参数进一步训练。==模型参数会发生改变==，能==让模型"长期"具备某种能力或知识==。
- **RAG（Retrieval-Augmented Generation）**是一种==将检索和LLM结合==的技术。在==不改变已有的模型参数==基础上，“外挂”知识库，增强模型能力。


| 维度 | 微调 | RAG |
|------|------|-----|
| **1.性能成本** | 训练代价高，推理成本小 | 无训练代价，推理时高 |
| **【1延申】更新频率** | 更新慢 | 更新快，甚至可以实时 |
| **【1延申】部署场景** | 要求时延低 | 时延不紧张  |
| **2.效果依赖** | 微调的数据质量和覆盖度 | 知识库的质量和检索质量 |
| **3.实际场景** | 客服（业务逻辑和特定话术）<br> 代码助手（特定语言和框架）<br> 医疗大模型、法律大模型……| 企业知识问答（内部知识库）<br> 学术助手（论文检索和引用） <br> 新闻助手、舆论问答等实时类场景 |
| **4.使用时机**| 让具备的风格话术、专业术语<br>知识变化不频繁，可定期更新<br>时延要求低 | 知识更新频繁、甚至实时<br>知识库私有或商业机密<br>答案有依据，知识可溯源|


**总结**：==微调是"改造"模型本身==，==RAG是"外挂"知识库==。微调适合==模型能力长期固化==，RAG适合==灵活扩展和实时更新知识==。

:::


::: details 问题2：微调时，全量微调和高效微调有什么区别？各自在什么时机用？

区别：
- **全量微调（Full Fine-tuning）**更新所有的模型参数，需要的数据量大、训练时间长，但效果往往比较好
- **高效微调（Parameter-Efficient Fine-tuning, PEFT）**更新少量的参数、训练快、效率高，效果也能接近全量微调。

| 维度 | 全量微调 | 高效微调 |
|------|----------|----------|
|**参数量**| 所有参数 | 少部分参数(1-10%) |
|**效果**| 通常最好| 接近全量微调|
|**训练速度**| 慢 | 快 |
|**数据需求**| 大量高质量数据 | 少量高质量数据 |
| **时机** | 数据、训练资源充足<br> 效果精度要求高 <br>  部署后很少更新| 数据有限<br>快速迭代 |
:::


::: details 问题3：PEFT分为哪几类？每一类有哪些代表方法？

![PEFT_methods.png](/images/PEFT_methods.png)

- **选择性方法**：==冻结大部分参数或层==，==**选择性**只微调某些参数或者层==。如：BitFit只调偏置项，freeze是冻结大部分层、只调少量层。
- **加性方法**：==**新增**少量参数或者层==，==只调新增的部分==。如：Prompt-Tuning添加软提示向量、Adapter添加小提示层、Prefix-Tuning、P-Tuning。
- **重参数化**：通过对模型的==权重矩阵进行低秩分解==，减少需要更新的参数。如：LoRA矩阵分解来减少更新的参数量。
:::

:::details 问题4：讲一下如何从头微调一个LLM，至上线并部署应用
step1: 选择模型，根据任务复杂度和算力情况（1B用多大模型？7B用多大模型？）
step2：选择数据，收集高质量业务数据（收集多少呢？1B用多少？7B用多少）
step3：选择框架，peft、魔搭社区 swift、ansloss
step4：训练
step5：评估调优
step6：部署上线
:::

### PEFT
![PEFT_methods.png](/images/PEFT_methods.png)

- **选择性方法**：==冻结大部分参数或层==，==**选择性**只微调某些参数或者层==。如：BitFit（只调偏置项），freeze（冻结大部分层、只调少量层）。
- **加性方法**：==**新增**少量参数或者层==，==只调新增的部分==。如：Prompt-Tuning（添加软提示向量）、Adapter（添加小提示层）、Prefix-Tuning、P-Tuning。
- **重参数化**：通过对模型的==权重矩阵进行低秩分解==，减少需要更新的参数。如：LoRA（矩阵分解来减少更新的参数量）。

#### 一、选择性方法

##### 1.1 Freeze
**基本原理**：冻结大部分层，只对==少部分层==的参数进行微调。一般，选择的是最后几层。

**优点**：节省显存，训练速度快，数据依赖少。大部分参数固定，模型大部分能力会保留，很少直接会崩坏掉。
**缺点**：选择固定哪几层，有很强的主观性。选择的多少和好坏会直接影响微调效果。于是，也出现了一些评估参数重要性的工作（DiffPruning、FishMask、FAR）


### LORA
### QLORA

### 