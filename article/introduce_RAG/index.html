<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.157" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><link rel="icon" type="image/jpg" href="/blogger.jpg"><title>RAG | majin</title><meta name="description" content=""><link rel="preload" href="/assets/style-DDKN9_aW.css" as="style"><link rel="stylesheet" href="/assets/style-DDKN9_aW.css"><link rel="modulepreload" href="/assets/app-KjTT_h7t.js"><link rel="modulepreload" href="/assets/index.html-C0xMhuJv.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-c65f7727><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-bed66c22></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-bed66c22> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-c65f7727 data-v-dc00e0f2><div class="vp-navbar" vp-navbar data-v-dc00e0f2 data-v-eca676eb><div class="wrapper" data-v-eca676eb><div class="container" data-v-eca676eb><div class="title" data-v-eca676eb><div class="vp-navbar-title" data-v-eca676eb data-v-4828c0fc><a class="vp-link link no-icon title" href="/" data-v-4828c0fc><!--[--><!--[--><!--]--><!----><span data-v-4828c0fc>majin</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-eca676eb><div class="content-body" data-v-eca676eb><!--[--><!--]--><div class="vp-navbar-search search" data-v-eca676eb><div class="search-wrapper" data-v-cb3e0943><!----><div id="local-search" data-v-cb3e0943><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-cb3e0943><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-eca676eb data-v-a86d55ed><span id="main-nav-aria-label" class="visually-hidden" data-v-a86d55ed>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/" tabindex="0" data-v-a86d55ed data-v-7a6bcf52><!--[--><!----><span data-v-7a6bcf52>首页</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/blog/" tabindex="0" data-v-a86d55ed data-v-7a6bcf52><!--[--><!----><span data-v-7a6bcf52>博客</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/blog/tags/" tabindex="0" data-v-a86d55ed data-v-7a6bcf52><!--[--><!----><span data-v-7a6bcf52>标签</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/blog/archives/" tabindex="0" data-v-a86d55ed data-v-7a6bcf52><!--[--><!----><span data-v-7a6bcf52>归档</span><!----><!--]--><!----></a><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-eca676eb data-v-c8c80ec6><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-c8c80ec6 data-v-d35535d4 data-v-d395b6c4><span class="check" data-v-d395b6c4><span class="icon" data-v-d395b6c4><!--[--><span class="vpi-sun sun" data-v-d35535d4></span><span class="vpi-moon moon" data-v-d35535d4></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-eca676eb data-v-ae0696b4 data-v-3c959de6><!--[--><a class="vp-social-link no-icon" href="/" aria-label="github" target="_blank" rel="noopener" data-v-3c959de6 data-v-eebc891d><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-eca676eb data-v-d73459e2 data-v-97091a75><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-97091a75><span class="vpi-more-horizontal icon" data-v-97091a75></span></button><div class="menu" data-v-97091a75><div class="vp-menu" data-v-97091a75 data-v-7d8c6914><!----><!--[--><!--[--><!----><div class="group" data-v-d73459e2><div class="item appearance" data-v-d73459e2><p class="label" data-v-d73459e2>外观</p><div class="appearance-action" data-v-d73459e2><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-d73459e2 data-v-d35535d4 data-v-d395b6c4><span class="check" data-v-d395b6c4><span class="icon" data-v-d395b6c4><!--[--><span class="vpi-sun sun" data-v-d35535d4></span><span class="vpi-moon moon" data-v-d35535d4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-d73459e2><div class="item social-links" data-v-d73459e2><div class="vp-social-links social-links-list" data-v-d73459e2 data-v-3c959de6><!--[--><a class="vp-social-link no-icon" href="/" aria-label="github" target="_blank" rel="noopener" data-v-3c959de6 data-v-eebc891d><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-eca676eb data-v-e737b135><span class="container" data-v-e737b135><span class="top" data-v-e737b135></span><span class="middle" data-v-e737b135></span><span class="bottom" data-v-e737b135></span></span></button></div></div></div></div><div class="divider" data-v-eca676eb><div class="divider-line" data-v-eca676eb></div></div></div><!----></header><div class="vp-local-nav fixed reached-top is-blog" data-v-c65f7727 data-v-6e03a609><button class="hidden menu" disabled aria-expanded="false" aria-controls="SidebarNav" data-v-6e03a609><span class="vpi-align-left menu-icon" data-v-6e03a609></span><span class="menu-text" data-v-6e03a609>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-6e03a609 data-v-d75301e9><button data-v-d75301e9>返回顶部</button><!----></div></div><!----><!--[--><div id="VPContent" vp-content class="vp-content" data-v-c65f7727 data-v-f95c1c5f><div class="vp-doc-container is-blog" data-v-f95c1c5f data-v-00837af9><!--[--><!--]--><div class="container" data-v-00837af9><!----><div class="content" data-v-00837af9><div class="content-container" data-v-00837af9><!--[--><!--]--><main class="main" data-v-00837af9><nav class="vp-breadcrumb" data-v-00837af9 data-v-d7544bfb><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-d7544bfb><!--[--><li property="itemListElement" typeof="ListItem" data-v-d7544bfb><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-d7544bfb><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-d7544bfb></span><meta property="name" content="首页" data-v-d7544bfb><meta property="position" content="1" data-v-d7544bfb></li><li property="itemListElement" typeof="ListItem" data-v-d7544bfb><a class="vp-link link breadcrumb" href="/blog/" property="item" typeof="WebPage" data-v-d7544bfb><!--[-->博客<!--]--><!----></a><span class="vpi-chevron-right" data-v-d7544bfb></span><meta property="name" content="博客" data-v-d7544bfb><meta property="position" content="2" data-v-d7544bfb></li><li property="itemListElement" typeof="ListItem" data-v-d7544bfb><a class="vp-link link breadcrumb" href="/blog/categories/?id=c615d2" property="item" typeof="WebPage" data-v-d7544bfb><!--[-->RAG<!--]--><!----></a><span class="vpi-chevron-right" data-v-d7544bfb></span><meta property="name" content="RAG" data-v-d7544bfb><meta property="position" content="3" data-v-d7544bfb></li><li property="itemListElement" typeof="ListItem" data-v-d7544bfb><a class="vp-link link breadcrumb current" href="/article/introduce_RAG/" property="item" typeof="WebPage" data-v-d7544bfb><!--[-->RAG<!--]--><!----></a><!----><meta property="name" content="RAG" data-v-d7544bfb><meta property="position" content="4" data-v-d7544bfb></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-d1b68b8b>RAG <!----></h1><div class="vp-doc-meta" data-v-d1b68b8b><!--[--><!--]--><p class="reading-time" data-v-d1b68b8b><span class="vpi-books icon" data-v-d1b68b8b></span><span data-v-d1b68b8b>约 1166 字</span><span data-v-d1b68b8b>大约 4 分钟</span></p><p data-v-d1b68b8b><span class="vpi-tag icon" data-v-d1b68b8b></span><!--[--><a class="vp-link link tag vp-tag-ymv4" href="/blog/tags/?tag=RAG" data-v-d1b68b8b><!--[-->RAG<!--]--><!----></a><!--]--></p><!--[--><!--]--><p class="create-time" data-v-d1b68b8b><span class="vpi-clock icon" data-v-d1b68b8b></span><span data-v-d1b68b8b>2025-12-21</span></p></div><!--]--><!--[--><!--]--><div class="_article_introduce_RAG_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-00837af9><!--[--><!--]--><div data-v-00837af9><h3 id="rag基本流程" tabindex="-1"><a class="header-anchor" href="#rag基本流程"><span>RAG基本流程</span></a></h3><ul><li><mark>离线</mark>：切分、索引</li><li><mark>在线</mark>：召回、重排、生成</li></ul><h4 id="离线-切分" tabindex="-1"><a class="header-anchor" href="#离线-切分"><span>（离线）切分</span></a></h4><ul><li>按句子分：太细太碎</li><li>按段落分：不均衡，可能会很长，可能会很多</li><li>按字数分：语义不连贯</li></ul><h4 id="离线-索引" tabindex="-1"><a class="header-anchor" href="#离线-索引"><span>（离线）索引</span></a></h4><ul><li>将每个chunk进行向量化表达，放入向量库中以备后续查询</li></ul><div class="hint-container tip"><p class="hint-container-title">常见面试题</p></div><details class="hint-container details"><summary>1. 如何向量化？模型怎么选的？有没有自己训练过？</summary></details><details class="hint-container details"><summary>2. 向量库有了解吗？向量库是怎么选择的？</summary></details><h4 id="在线-召回" tabindex="-1"><a class="header-anchor" href="#在线-召回"><span>（在线）召回</span></a></h4><p>纯向量的泛化性好，但对精确符号、专属名词不敏感； 文本召回能解决精准匹配、且召回可控，稳定性好； 两者互补</p><ul><li>向量召回： <ul><li>用户query进行emb后，跟库中的每个索引向量（矩阵运算） 计算相似度；</li><li>计算相似度的方法：余弦、欧式距离、点积</li><li><strong>核心</strong>：“能解决用户<mark>想表达什么</mark>”</li><li><strong>优势</strong>：<mark>泛化性</mark>，近似语义理解（谷歌/必应/搜索引擎）、跨语言理解（谷歌浏览器/chrome）、容错性（拼写错误、模糊表述）</li><li><strong>不足</strong>：缩写词和短语（忍3、“楠”得一见）、搜索具体专有名词（歌名+歌名的remix）和人名可能会飘逸（马丁-&gt;马丁内斯）</li></ul></li><li>文本&amp;图谱召回（倒排）： <ul><li>提取领域实体 -&gt; 实体文本多路召回：原词，n-gram，拼音，拼音首字母</li><li>实体 -&gt; 文本：实体属性，周围一跳的信息描述（模板）</li><li>文本检索引擎：ElasticSearch</li></ul></li></ul><h4 id="在线-重排" tabindex="-1"><a class="header-anchor" href="#在线-重排"><span>（在线）重排</span></a></h4><ol><li><p>重排可以<mark>融合多路召回的结果</mark></p></li><li><p>在单路召回情况下，依然能<mark>提升准确率</mark>。相关≠可用（RAG需要的是能不能解决问题，而不是是否相关）</p><p>具体来说，召回返回的分数是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>d</mi><mi>o</mi><mi>c</mi><mo>∈</mo><mtext>同一主题</mtext><mi mathvariant="normal">∣</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(doc \in 同一主题|query)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">oc</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">同一主题</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em;">ery</span><span class="mclose">)</span></span></span></span> ，重排返回的分数是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>d</mi><mi>o</mi><mi>c</mi><mtext>解决</mtext><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(doc 解决 query|query)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">oc</span><span class="mord cjk_fallback">解决</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em;">ery</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em;">ery</span><span class="mclose">)</span></span></span></span></p><p>再比如，原始query：<code>transformer为什么需要PE？</code>，</p><p>召回1：<code>transformer是一种基于self-attention结构的模型，广泛应用于XXX</code></p><p>召回2：<code>由于self-attention对输入顺序不敏感，必须通过引入PE来注入位置信息</code></p><p>召回1的召回分数很高（主题匹配高）、但没法回答问题（无关问题）</p><p>召回2的召回分数较低（主题匹配低）、但可以回答问题（命中问题）</p></li></ol><p><img src="/images/rag/Embedding_bi_encoder.png" alt="Embedding_bi_encoder"><img src="/images/rag/Rerank_cross_encoder.png" alt="Rerank_cross_encoder"></p><ul><li>Embedding模型本质上是双编码器，文本内部没有任何交互，只有最后输出结果时，两个结果才会唯一一次交互。</li><li>ReRank模型是Cross-encoder的模型，一开始就通过transformer进行交互。</li></ul><table><thead><tr><th></th><th>召回</th><th>重排</th></tr></thead><tbody><tr><td>关注点</td><td>刻画相似度，”跟query是不是相关“</td><td>刻画能用性，”能不能解决query“</td></tr><tr><td>原理</td><td>embedding模型+向量相似度</td><td>cross-encoder =&gt; 分数</td></tr><tr><td>优点</td><td>成本低；快（预计算好一半，在线计算很少）</td><td>准确</td></tr><tr><td>缺点</td><td>不准确</td><td>成本高；慢（相比召回，没有预计算内容）</td></tr><tr><td>场景</td><td>在大规模后选中，初步筛选</td><td>在部分候选上，进一步精挑细选</td></tr></tbody></table><h4 id="在线-生成" tabindex="-1"><a class="header-anchor" href="#在线-生成"><span>（在线）生成</span></a></h4><p>将召回+重排后的片段，拼接prompt+原始问题，输入给大模型，输出最终答案。</p><div class="hint-container tip"><p class="hint-container-title">常见面试题</p></div><details class="hint-container details"><summary>1. 为什么需要重排？直接用召回的相似度不行吗？</summary><p>片段相似 ≠ 语义相关。 比如：transformer为什么需要PE？ 检索到：transformer是一种基于self-attention的模型结构，被广泛应用于NLP。 两者片段相似，但是语义是不相关的</p></details><details class="hint-container details"><summary>2.怎么提高召回准确率和覆盖率？</summary><p>使用多路召回、过滤、rerank</p></details><details class="hint-container details"><summary>3.怎么改进embedding模型？怎么训练？</summary></details><details class="hint-container details"><summary>4.怎么改进rerank模型？怎么训练？</summary></details><h3 id="评估rag系统" tabindex="-1"><a class="header-anchor" href="#评估rag系统"><span>评估RAG系统</span></a></h3><ul><li>召回率（recall）：能不能从库中尽可能的把相关的召回来。“召回十个，里面有多少个是相关的 ” 除以 “库中有多少个相关的”</li><li>精确率（precision）：召回的东西，有多少是相关的。“召回十个，里面有多少个是相关的 ” 除以 “召回了多少个（十个）”</li><li>响应时延（Latency）：提问到生成答案的时间</li></ul><h3 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考：</span></a></h3><ul><li><a href="https://www.bilibili.com/video/BV1JLN2z4EZQ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=748cb51f7cdac32f173ae1c569bfb80d" target="_blank" rel="noopener noreferrer">Bilibili: RAG 工作机制详解——一个高质量知识库背后的技术全流程</a></li><li><a href="https://github.com/netease-youdao/QAnything/wiki/RAG%E7%B3%BB%E7%BB%9F%EF%BC%9A%E6%95%B0%E6%8D%AE%E8%B6%8A%E5%A4%9A%E6%95%88%E6%9E%9C%E8%B6%8A%E5%A5%BD%E5%90%97%EF%BC%9F" target="_blank" rel="noopener noreferrer">Github: RAG系统：数据越多效果越好吗？</a></li><li><a href="https://zhuanlan.zhihu.com/p/29949362142" target="_blank" rel="noopener noreferrer">知乎：embedding那些事</a></li><li><a href="https://zhuanlan.zhihu.com/p/29977179977" target="_blank" rel="noopener noreferrer">知乎：rerank那些事</a></li><li><a href="https://xuqiwei1986.feishu.cn/wiki/Mmt0wpQo6iDHAyky5fzcZbvBnih" target="_blank" rel="noopener noreferrer">飞书：混合检索和重排序改进RAG</a></li></ul></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-00837af9 data-v-6c6ea141><!--[--><!--]--><!----><div class="contributors" aria-label="Contributors" data-v-6c6ea141><span class="contributors-label" data-v-6c6ea141>贡献者: </span><span class="contributors-info" data-v-6c6ea141><!--[--><!--[--><span class="contributor" data-v-6c6ea141>majinsuper</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-6c6ea141><div class="pager" data-v-6c6ea141><a class="vp-link link pager-link prev" href="/article/advanced_RAG/" data-v-6c6ea141><!--[--><span class="desc" data-v-6c6ea141>上一页</span><span class="title" data-v-6c6ea141>RAG进阶</span><!--]--><!----></a></div><div class="pager" data-v-6c6ea141><a class="vp-link link pager-link next" href="/article/transformer_FNN/" data-v-6c6ea141><!--[--><span class="desc" data-v-6c6ea141>下一页</span><span class="title" data-v-6c6ea141>FNN</span><!--]--><!----></a></div></nav></footer><!----><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button type="button" class="vp-back-to-top" aria-label="back to top" data-v-c65f7727 style="display:none;" data-v-fc53d5da><span class="percent" data-allow-mismatch data-v-fc53d5da>0%</span><span class="show icon vpi-back-to-top" data-v-fc53d5da></span><svg aria-hidden="true" data-v-fc53d5da><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-fc53d5da></circle></svg></button><footer class="vp-footer" vp-footer data-v-c65f7727 data-v-20b8cfc9><!--[--><div class="container" data-v-20b8cfc9><!----><!----></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-KjTT_h7t.js" defer></script></body></html>