import{_ as s,c as t,b as e,o as n}from"./app-KjTT_h7t.js";const r="/images/rag/Embedding_bi_encoder.png",i="/images/rag/Rerank_cross_encoder.png",m={};function l(o,a){return n(),t("div",null,[...a[0]||(a[0]=[e('<h3 id="rag基本流程" tabindex="-1"><a class="header-anchor" href="#rag基本流程"><span>RAG基本流程</span></a></h3><ul><li><mark>离线</mark>：切分、索引</li><li><mark>在线</mark>：召回、重排、生成</li></ul><h4 id="离线-切分" tabindex="-1"><a class="header-anchor" href="#离线-切分"><span>（离线）切分</span></a></h4><ul><li>按句子分：太细太碎</li><li>按段落分：不均衡，可能会很长，可能会很多</li><li>按字数分：语义不连贯</li></ul><h4 id="离线-索引" tabindex="-1"><a class="header-anchor" href="#离线-索引"><span>（离线）索引</span></a></h4><ul><li>将每个chunk进行向量化表达，放入向量库中以备后续查询</li></ul><div class="hint-container tip"><p class="hint-container-title">常见面试题</p></div><details class="hint-container details"><summary>1. 如何向量化？模型怎么选的？有没有自己训练过？</summary></details><details class="hint-container details"><summary>2. 向量库有了解吗？向量库是怎么选择的？</summary></details><h4 id="在线-召回" tabindex="-1"><a class="header-anchor" href="#在线-召回"><span>（在线）召回</span></a></h4><p>纯向量的泛化性好，但对精确符号、专属名词不敏感； 文本召回能解决精准匹配、且召回可控，稳定性好； 两者互补</p><ul><li>向量召回： <ul><li>用户query进行emb后，跟库中的每个索引向量（矩阵运算） 计算相似度；</li><li>计算相似度的方法：余弦、欧式距离、点积</li><li><strong>核心</strong>：“能解决用户<mark>想表达什么</mark>”</li><li><strong>优势</strong>：<mark>泛化性</mark>，近似语义理解（谷歌/必应/搜索引擎）、跨语言理解（谷歌浏览器/chrome）、容错性（拼写错误、模糊表述）</li><li><strong>不足</strong>：缩写词和短语（忍3、“楠”得一见）、搜索具体专有名词（歌名+歌名的remix）和人名可能会飘逸（马丁-&gt;马丁内斯）</li></ul></li><li>文本&amp;图谱召回（倒排）： <ul><li>提取领域实体 -&gt; 实体文本多路召回：原词，n-gram，拼音，拼音首字母</li><li>实体 -&gt; 文本：实体属性，周围一跳的信息描述（模板）</li><li>文本检索引擎：ElasticSearch</li></ul></li></ul><h4 id="在线-重排" tabindex="-1"><a class="header-anchor" href="#在线-重排"><span>（在线）重排</span></a></h4><ol><li><p>重排可以<mark>融合多路召回的结果</mark></p></li><li><p>在单路召回情况下，依然能<mark>提升准确率</mark>。相关≠可用（RAG需要的是能不能解决问题，而不是是否相关）</p><p>具体来说，召回返回的分数是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>d</mi><mi>o</mi><mi>c</mi><mo>∈</mo><mtext>同一主题</mtext><mi mathvariant="normal">∣</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(doc \\in 同一主题|query)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">oc</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">同一主题</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em;">ery</span><span class="mclose">)</span></span></span></span> ，重排返回的分数是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>d</mi><mi>o</mi><mi>c</mi><mtext>解决</mtext><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(doc 解决 query|query)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">oc</span><span class="mord cjk_fallback">解决</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em;">ery</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.03588em;">ery</span><span class="mclose">)</span></span></span></span></p><p>再比如，原始query：<code>transformer为什么需要PE？</code>，</p><p>召回1：<code>transformer是一种基于self-attention结构的模型，广泛应用于XXX</code></p><p>召回2：<code>由于self-attention对输入顺序不敏感，必须通过引入PE来注入位置信息</code></p><p>召回1的召回分数很高（主题匹配高）、但没法回答问题（无关问题）</p><p>召回2的召回分数较低（主题匹配低）、但可以回答问题（命中问题）</p></li></ol><p><img src="'+r+'" alt="Embedding_bi_encoder"><img src="'+i+'" alt="Rerank_cross_encoder"></p><ul><li>Embedding模型本质上是双编码器，文本内部没有任何交互，只有最后输出结果时，两个结果才会唯一一次交互。</li><li>ReRank模型是Cross-encoder的模型，一开始就通过transformer进行交互。</li></ul><table><thead><tr><th></th><th>召回</th><th>重排</th></tr></thead><tbody><tr><td>关注点</td><td>刻画相似度，”跟query是不是相关“</td><td>刻画能用性，”能不能解决query“</td></tr><tr><td>原理</td><td>embedding模型+向量相似度</td><td>cross-encoder =&gt; 分数</td></tr><tr><td>优点</td><td>成本低；快（预计算好一半，在线计算很少）</td><td>准确</td></tr><tr><td>缺点</td><td>不准确</td><td>成本高；慢（相比召回，没有预计算内容）</td></tr><tr><td>场景</td><td>在大规模后选中，初步筛选</td><td>在部分候选上，进一步精挑细选</td></tr></tbody></table><h4 id="在线-生成" tabindex="-1"><a class="header-anchor" href="#在线-生成"><span>（在线）生成</span></a></h4><p>将召回+重排后的片段，拼接prompt+原始问题，输入给大模型，输出最终答案。</p><div class="hint-container tip"><p class="hint-container-title">常见面试题</p></div><details class="hint-container details"><summary>1. 为什么需要重排？直接用召回的相似度不行吗？</summary><p>片段相似 ≠ 语义相关。 比如：transformer为什么需要PE？ 检索到：transformer是一种基于self-attention的模型结构，被广泛应用于NLP。 两者片段相似，但是语义是不相关的</p></details><details class="hint-container details"><summary>2.怎么提高召回准确率和覆盖率？</summary><p>使用多路召回、过滤、rerank</p></details><details class="hint-container details"><summary>3.怎么改进embedding模型？怎么训练？</summary></details><details class="hint-container details"><summary>4.怎么改进rerank模型？怎么训练？</summary></details><h3 id="评估rag系统" tabindex="-1"><a class="header-anchor" href="#评估rag系统"><span>评估RAG系统</span></a></h3><ul><li>召回率（recall）：能不能从库中尽可能的把相关的召回来。“召回十个，里面有多少个是相关的 ” 除以 “库中有多少个相关的”</li><li>精确率（precision）：召回的东西，有多少是相关的。“召回十个，里面有多少个是相关的 ” 除以 “召回了多少个（十个）”</li><li>响应时延（Latency）：提问到生成答案的时间</li></ul><h3 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考：</span></a></h3><ul><li><a href="https://www.bilibili.com/video/BV1JLN2z4EZQ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=748cb51f7cdac32f173ae1c569bfb80d" target="_blank" rel="noopener noreferrer">Bilibili: RAG 工作机制详解——一个高质量知识库背后的技术全流程</a></li><li><a href="https://github.com/netease-youdao/QAnything/wiki/RAG%E7%B3%BB%E7%BB%9F%EF%BC%9A%E6%95%B0%E6%8D%AE%E8%B6%8A%E5%A4%9A%E6%95%88%E6%9E%9C%E8%B6%8A%E5%A5%BD%E5%90%97%EF%BC%9F" target="_blank" rel="noopener noreferrer">Github: RAG系统：数据越多效果越好吗？</a></li><li><a href="https://zhuanlan.zhihu.com/p/29949362142" target="_blank" rel="noopener noreferrer">知乎：embedding那些事</a></li><li><a href="https://zhuanlan.zhihu.com/p/29977179977" target="_blank" rel="noopener noreferrer">知乎：rerank那些事</a></li><li><a href="https://xuqiwei1986.feishu.cn/wiki/Mmt0wpQo6iDHAyky5fzcZbvBnih" target="_blank" rel="noopener noreferrer">飞书：混合检索和重排序改进RAG</a></li></ul>',28)])])}const c=s(m,[["render",l]]),d=JSON.parse('{"path":"/article/introduce_RAG/","title":"RAG","lang":"zh-CN","frontmatter":{"title":"RAG","tags":["RAG"],"createTime":"2025-12-21T10:44:31.000Z","permalink":"/article/introduce_RAG/"},"readingTime":{"minutes":3.89,"words":1166},"git":{"createdTime":1766377947000,"updatedTime":1766379717000,"contributors":[{"name":"majinsuper","username":"majinsuper","email":"1533363937@qq.com","commits":15,"avatar":"https://avatars.githubusercontent.com/majinsuper?v=4","url":"https://github.com/majinsuper"}]},"filePathRelative":"5.RAG/RAG.md","headers":[],"categoryList":[{"id":"c615d2","sort":5,"name":"RAG"}]}');export{c as comp,d as data};
