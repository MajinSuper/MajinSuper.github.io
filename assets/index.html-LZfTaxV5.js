import{_ as a,c as n,a as s,o as e}from"./app-70rzAZhs.js";const r="/images/PEFT_methods.png",i={};function d(o,t){return e(),n("div",null,[...t[0]||(t[0]=[s('<h2 id="训练与微调" tabindex="-1"><a class="header-anchor" href="#训练与微调"><span>训练与微调</span></a></h2><h3 id="基本概念" tabindex="-1"><a class="header-anchor" href="#基本概念"><span>基本概念</span></a></h3><p>微调（Fine-tuning）是指在已经预训练好的大模型基础上，利用<mark>特定领域或任务的数据</mark>对模型进行再次训练的过程。</p><p><mark>主要目的</mark>是让模型更好地适应特定应用场景，提高在<mark>特定任务上的表现</mark>。通过微调，可以让通用大模型具备更强的专业能力、理解特定领域的术语和知识，或者更好地满足用户的个性化需求。</p><div class="hint-container tip"><p class="hint-container-title">常见面试题</p></div><details class="hint-container details"><summary>问题1. 微调和RAG的区别,什么时候用微调？什么时候用RAG？</summary><p>基本区别：</p><ul><li>**微调（Fine-tuning）**是在已有的大模型上，针对<mark>领域数据或领域任务</mark>，对模型参数进一步训练。<mark>模型参数会发生改变</mark>，能<mark>让模型&quot;长期&quot;具备某种能力或知识</mark>。</li><li>**RAG（Retrieval-Augmented Generation）**是一种<mark>将检索和LLM结合</mark>的技术。在<mark>不改变已有的模型参数</mark>基础上，“外挂”知识库，增强模型能力。</li></ul><table><thead><tr><th>维度</th><th>微调</th><th>RAG</th></tr></thead><tbody><tr><td><strong>1.性能成本</strong></td><td>训练代价高，推理成本小</td><td>无训练代价，推理时高</td></tr><tr><td><strong>【1延申】更新频率</strong></td><td>更新慢</td><td>更新快，甚至可以实时</td></tr><tr><td><strong>【1延申】部署场景</strong></td><td>要求时延低</td><td>时延不紧张</td></tr><tr><td><strong>2.效果依赖</strong></td><td>微调的数据质量和覆盖度</td><td>知识库的质量和检索质量</td></tr><tr><td><strong>3.实际场景</strong></td><td>客服（业务逻辑和特定话术）<br> 代码助手（特定语言和框架）<br> 医疗大模型、法律大模型……</td><td>企业知识问答（内部知识库）<br> 学术助手（论文检索和引用） <br> 新闻助手、舆论问答等实时类场景</td></tr><tr><td><strong>4.使用时机</strong></td><td>让具备的风格话术、专业术语<br>知识变化不频繁，可定期更新<br>时延要求低</td><td>知识更新频繁、甚至实时<br>知识库私有或商业机密<br>答案有依据，知识可溯源</td></tr></tbody></table><p><strong>总结</strong>：<mark>微调是&quot;改造&quot;模型本身</mark>，<mark>RAG是&quot;外挂&quot;知识库</mark>。微调适合<mark>模型能力长期固化</mark>，RAG适合<mark>灵活扩展和实时更新知识</mark>。</p></details><details class="hint-container details"><summary>问题2：微调时，全量微调和高效微调有什么区别？各自在什么时机用？</summary><p>区别：</p><ul><li>**全量微调（Full Fine-tuning）**更新所有的模型参数，需要的数据量大、训练时间长，但效果往往比较好</li><li>**高效微调（Parameter-Efficient Fine-tuning, PEFT）**更新少量的参数、训练快、效率高，效果也能接近全量微调。</li></ul><table><thead><tr><th>维度</th><th>全量微调</th><th>高效微调</th></tr></thead><tbody><tr><td><strong>参数量</strong></td><td>所有参数</td><td>少部分参数(1-10%)</td></tr><tr><td><strong>效果</strong></td><td>通常最好</td><td>接近全量微调</td></tr><tr><td><strong>训练速度</strong></td><td>慢</td><td>快</td></tr><tr><td><strong>数据需求</strong></td><td>大量高质量数据</td><td>少量高质量数据</td></tr><tr><td><strong>时机</strong></td><td>数据、训练资源充足<br> 效果精度要求高 <br> 部署后很少更新</td><td>数据有限<br>快速迭代</td></tr></tbody></table></details><details class="hint-container details"><summary>问题3：PEFT分为哪几类？每一类有哪些代表方法？</summary><p><img src="'+r+'" alt="PEFT_methods.png"></p><ul><li><strong>选择性方法</strong>：<mark>冻结大部分参数或层</mark>，<mark><strong>选择性</strong>只微调某些参数或者层</mark>。如：BitFit只调偏置项，freeze是冻结大部分层、只调少量层。</li><li><strong>加性方法</strong>：<mark><strong>新增</strong>少量参数或者层</mark>，<mark>只调新增的部分</mark>。如：Prompt-Tuning添加软提示向量、Adapter添加小提示层、Prefix-Tuning、P-Tuning。</li><li><strong>重参数化</strong>：通过对模型的<mark>权重矩阵进行低秩分解</mark>，减少需要更新的参数。如：LoRA矩阵分解来减少更新的参数量。</li></ul></details><details class="hint-container details"><summary>问题4：讲一下如何从头微调一个LLM，至上线并部署应用</summary><p>step1: 选择模型，根据任务复杂度和算力情况（1B用多大模型？7B用多大模型？） step2：选择数据，收集高质量业务数据（收集多少呢？1B用多少？7B用多少） step3：选择框架，peft、魔搭社区 swift、ansloss step4：训练 step5：评估调优 step6：部署上线</p></details><h3 id="peft" tabindex="-1"><a class="header-anchor" href="#peft"><span>PEFT</span></a></h3><p><img src="'+r+'" alt="PEFT_methods.png"></p><ul><li><strong>选择性方法</strong>：<mark>冻结大部分参数或层</mark>，<mark><strong>选择性</strong>只微调某些参数或者层</mark>。如：BitFit（只调偏置项），freeze（冻结大部分层、只调少量层）。</li><li><strong>加性方法</strong>：<mark><strong>新增</strong>少量参数或者层</mark>，<mark>只调新增的部分</mark>。如：Prompt-Tuning（添加软提示向量）、Adapter（添加小提示层）、Prefix-Tuning、P-Tuning。</li><li><strong>重参数化</strong>：通过对模型的<mark>权重矩阵进行低秩分解</mark>，减少需要更新的参数。如：LoRA（矩阵分解来减少更新的参数量）。</li></ul><h4 id="一、选择性方法" tabindex="-1"><a class="header-anchor" href="#一、选择性方法"><span>一、选择性方法</span></a></h4><h5 id="_1-1-freeze" tabindex="-1"><a class="header-anchor" href="#_1-1-freeze"><span>1.1 Freeze</span></a></h5><p><strong>基本原理</strong>：冻结大部分层，只对<mark>少部分层</mark>的参数进行微调。一般，选择的是最后几层。</p><p><strong>优点</strong>：节省显存，训练速度快，数据依赖少。大部分参数固定，模型大部分能力会保留，很少直接会崩坏掉。 <strong>缺点</strong>：选择固定哪几层，有很强的主观性。选择的多少和好坏会直接影响微调效果。于是，也出现了一些评估参数重要性的工作（DiffPruning、FishMask、FAR）</p><h3 id="lora" tabindex="-1"><a class="header-anchor" href="#lora"><span>LORA</span></a></h3><h3 id="qlora" tabindex="-1"><a class="header-anchor" href="#qlora"><span>QLORA</span></a></h3><h3 id="" tabindex="-1"><a class="header-anchor" href="#"><span></span></a></h3>',19)])])}const l=a(i,[["render",d]]),g=JSON.parse('{"path":"/article/finetuning/","title":"训练与微调","lang":"zh-CN","frontmatter":{"title":"训练与微调","tags":["LLM","微调"],"createTime":"2025-09-20T09:44:31.000Z","permalink":"/article/finetuning/"},"readingTime":{"minutes":4.3,"words":1290},"git":{"createdTime":1753806061000,"updatedTime":1758362355000,"contributors":[{"name":"MajinSuper","username":"MajinSuper","email":"1533363937@qq.com","commits":1,"avatar":"https://avatars.githubusercontent.com/MajinSuper?v=4","url":"https://github.com/MajinSuper"},{"name":"majinsuper","username":"majinsuper","email":"1533363937@qq.com","commits":3,"avatar":"https://avatars.githubusercontent.com/majinsuper?v=4","url":"https://github.com/majinsuper"}]},"filePathRelative":"2.LLM/finetuning/训练与微调.md","headers":[],"categoryList":[{"id":"739f07","sort":2,"name":"LLM"},{"id":"aa92a3","sort":10003,"name":"finetuning"}]}');export{l as comp,g as data};
